{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "esg_documents_df = pd.read_csv('./dax_esg_media_dataset/esg_documents_for_dax_companies.csv', sep='|')\n",
    "# main columns: symbol, content (full document text), esg_topics\n",
    "\n",
    "sdg_descriptions_with_targets_df = pd.read_csv('./dax_esg_media_dataset/sdg_descriptions_with_targetsText.csv')\n",
    "# haven't really looked into this one yet, but it could be useful\n",
    "\n",
    "sp500_risk_ratings_df = pd.read_csv('./sp500_esg_risk_ratings/sp500_esg_risk_ratings.csv')\n",
    "\n",
    "# public_esg_ratings_df = pd.read_csv('./public_companies_esg_ratings.csv')\n",
    "# main columns: symbol, Total ESG Risk score, Environment Risk Score, Governance Risk Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  symbol environment_level\n",
      "0    DTE              High\n",
      "1    MRK              High\n",
      "2    HEI            Medium\n",
      "3    LIN            Medium\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# keep only the unique symbols (NOTE: this will only keep the first occurrence for each company, not sure how this will impact our later processing)\n",
    "\n",
    "# public_esg_ratings_df['ticker'] = public_esg_ratings_df['ticker'].str.upper()\n",
    "\n",
    "esg_documents_df = esg_documents_df.drop_duplicates(subset='symbol')\n",
    "\n",
    "# merged_df = pd.merge(esg_documents_df, public_esg_ratings_df, left_on='symbol', right_on='ticker', how='inner')\n",
    "\n",
    "# print the columns, which shows that we now have the ESG risk scores as columns\n",
    "# print(merged_df.columns)\n",
    "\n",
    "# print the first row\n",
    "# print(merged_df.head(1))\n",
    "\n",
    "# print the AAPL row\n",
    "# print(merged_df.loc[merged_df['symbol'] == 'AAPL']['Environment Risk Score'])\n",
    "print(merged_df[['symbol', 'environment_level']])\n",
    "print(len(merged_df))\n",
    "# very small overlap :(\n",
    "# print(esg_documents_df.columns)\n",
    "# print(public_esg_ratings_df.columns)\n",
    "\n",
    "# print(sorted(public_esg_ratings_df['ticker'].unique())[:10])  # View first 10 unique tickers\n",
    "# print(sorted(esg_documents_df['symbol'].unique())[:10])      # View first 10 unique symbols\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0              company  \\\n",
      "0           2        Beiersdorf AG   \n",
      "1           3  Deutsche Telekom AG   \n",
      "2           5           Vonovia SE   \n",
      "3           6           Merck KGaA   \n",
      "4           9                  MTU   \n",
      "\n",
      "                                             content               datatype  \\\n",
      "0  Sustainability Highlight Report CARE BEYOND SK...  sustainability_report   \n",
      "1  Corporate Responsibility Report 2021 2 Content...  sustainability_report   \n",
      "2  VONOVIA SE SUSTAINABILITY REPORT 2021 =For a S...  sustainability_report   \n",
      "3  Sustainability Report 2021 TABLE OF CONTENTS S...  sustainability_report   \n",
      "4  Our ideas and concepts FOR A SUSTAINABLE FUTUR...  sustainability_report   \n",
      "\n",
      "         date domain                                         esg_topics  \\\n",
      "0  2021-03-31    NaN  ['CleanWater', 'GHGEmission', 'ProductLiabilit...   \n",
      "1  2021-03-31    NaN  ['DataSecurity', 'Iso50001', 'GlobalWarming', ...   \n",
      "2  2021-03-31    NaN  ['Whistleblowing', 'DataSecurity', 'Vaccine', ...   \n",
      "3  2021-03-31    NaN  ['DataSecurity', 'DataMisuse', 'DrugResistance...   \n",
      "4  2020-03-31    NaN  ['WorkLifeBalance', 'Corruption', 'AirQuality'...   \n",
      "\n",
      "   internal symbol                                         title  ... ğ—¡ğ—²ğ˜„ğ˜€  \\\n",
      "0         1    BEI       BeiersdorfAG Sustainability Report 2021  ...    0   \n",
      "1         1    DTE  DeutscheTelekomAG Sustainability Report 2021  ...    0   \n",
      "2         1    VNA          VonoviaSE Sustainability Report 2021  ...    0   \n",
      "3         1    MRK          MerckKGaA Sustainability Report 2021  ...    0   \n",
      "4         1    MTX     MTUAeroEngines Sustainability Report 2020  ...    0   \n",
      "\n",
      "   ğ—§ğ—¿ğ—®ğ—»ğ˜€ğ—¶ğ˜ğ—¶ğ—¼ğ—»  ğ—¬ğ—²ğ—®ğ—¿  ğ™ğ™šğ™¢ğ™šğ™¢ğ™—ğ™šğ™§  ğ™£ğ™–ğ™¢ğ™šdo  ğ™©ğ™ğ™š  ğŸ•ğŸ  ğŸ­ğŸ³  ğŸ®ğŸ¬  ğŸ®ğŸ¬ğŸ®ğŸ®  \n",
      "0           0     0         0       0    0   0   0   0     0  \n",
      "1           0     0         0       0    0   0   0   0     0  \n",
      "2           0     0         0       0    0   0   0   0     0  \n",
      "3           0     0         0       0    0   0   0   0     0  \n",
      "4           0     0         0       0    0   0   0   0     0  \n",
      "\n",
      "[5 rows x 245686 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    token_pattern=r'\\b\\w+\\b' # Only keep word tokens\n",
    ")\n",
    "\n",
    "# Fit and transform the content column directly\n",
    "bow_matrix = vectorizer.fit_transform(esg_documents_df['content'].fillna(''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO here we should try and build a model that correlates the preprocessed\n",
    "# data to the column of our choice in the sp500_risk_ratings dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check how well our model did here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sources\n",
    "- https://www.kaggle.com/datasets/pritish509/s-and-p-500-esg-risk-ratings\n",
    "- https://www.kaggle.com/datasets/equintel/dax-esg-media-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
